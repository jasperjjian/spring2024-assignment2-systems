<?xml version="1.0" encoding="utf-8"?><testsuites><testsuite name="pytest" errors="0" failures="2" skipped="0" tests="18" time="44.301" timestamp="2024-05-03T20:18:59.608118" hostname="ad12a3ca-02.cloud.together.ai"><testcase classname="tests.test_ddp" name="test_DistributedDataParallelCPU[0.0016-ToyModel]" time="4.551" /><testcase classname="tests.test_ddp" name="test_DistributedDataParallelCPU[0.0016-ToyModelWithTiedWeights]" time="4.123" /><testcase classname="tests.test_ddp" name="test_DistributedDataParallelCPU[0.0001-ToyModel]" time="4.136" /><testcase classname="tests.test_ddp" name="test_DistributedDataParallelCPU[0.0001-ToyModelWithTiedWeights]" time="4.189" /><testcase classname="tests.test_ddp" name="test_DistributedDataParallelCPU[0.01-ToyModel]" time="5.141" /><testcase classname="tests.test_ddp" name="test_DistributedDataParallelCPU[0.01-ToyModelWithTiedWeights]" time="3.981" /><testcase classname="tests.test_ddp_individual_parameters" name="test_DistributedDataParallelIndividualParameters[ToyModel]" time="3.904" /><testcase classname="tests.test_ddp_individual_parameters" name="test_DistributedDataParallelIndividualParameters[ToyModelWithTiedWeights]" time="3.875" /><testcase classname="tests.test_rmsnorm" name="test_rmsnorm_forward_pass_pytorch" time="0.022" /><testcase classname="tests.test_rmsnorm" name="test_rmsnorm_forward_pass_triton" time="0.811" /><testcase classname="tests.test_rmsnorm" name="test_rmsnorm_backward_x_pytorch" time="0.239" /><testcase classname="tests.test_rmsnorm" name="test_rmsnorm_backward_g_pytorch" time="0.001" /><testcase classname="tests.test_rmsnorm" name="test_rmsnorm_backward_x_triton" time="0.124" /><testcase classname="tests.test_rmsnorm" name="test_rmsnorm_backward_g_triton" time="0.008" /><testcase classname="tests.test_rmsnorm" name="test_rmsnorm_autograd_pytorch_forward_backward" time="0.001" /><testcase classname="tests.test_rmsnorm" name="test_rmsnorm_autograd_triton_forward_backward" time="0.008" /><testcase classname="tests.test_sharded_optimizer" name="test_sharded_optimizer[ToyModel]" time="3.266"><failure message="torch.multiprocessing.spawn.ProcessRaisedException: &#10;&#10;-- Process 0 terminated with the following error:&#10;Traceback (most recent call last):&#10;  File &quot;/home/c-jjian/assignments/spring2024-assignment2-systems/336_a2_test_venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py&quot;, line 68, in _wrap&#10;    fn(i, *args)&#10;  File &quot;/home/c-jjian/assignments/spring2024-assignment2-systems/cs336-systems/tests/test_sharded_optimizer.py&quot;, line 48, in _test_sharded_optimizer&#10;    sharded_optimizer = get_sharded_optimizer(&#10;  File &quot;/home/c-jjian/assignments/spring2024-assignment2-systems/cs336-systems/tests/adapters.py&quot;, line 194, in get_sharded_optimizer&#10;    raise NotImplementedError&#10;NotImplementedError">model_class = &lt;class 'tests.common.ToyModel'&gt;

    @pytest.mark.parametrize("model_class", [ToyModel, ToyModelWithTiedWeights])
    def test_sharded_optimizer(model_class):
        world_size = 2
&gt;       mp.spawn(
            _test_sharded_optimizer,
            args=(world_size, model_class),
            nprocs=world_size,
            join=True,
        )

cs336-systems/tests/test_sharded_optimizer.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
336_a2_test_venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:241: in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
336_a2_test_venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:197: in start_processes
    while not context.join():
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;torch.multiprocessing.spawn.ProcessContext object at 0x1532a49bc940&gt;, timeout = None

    def join(self, timeout=None):
        r"""Join one or more processes within spawn context.
    
        Attempt to join one or more processes in this spawn context.
        If one of them exited with a non-zero exit status, this function
        kills the remaining processes and raises an exception with the cause
        of the first process exiting.
    
        Returns ``True`` if all processes have been joined successfully,
        ``False`` if there are more processes that need to be joined.
    
        Args:
            timeout (float): Wait this long before giving up on waiting.
        """
        # Ensure this function can be called even when we're done.
        if len(self.sentinels) == 0:
            return True
    
        # Wait for any process to fail or all of them to succeed.
        ready = multiprocessing.connection.wait(
            self.sentinels.keys(),
            timeout=timeout,
        )
    
        error_index = None
        for sentinel in ready:
            index = self.sentinels.pop(sentinel)
            process = self.processes[index]
            process.join()
            if process.exitcode != 0:
                error_index = index
                break
    
        # Return if there was no error.
        if error_index is None:
            # Return whether or not all processes have been joined.
            return len(self.sentinels) == 0
    
        # Assume failure. Terminate processes that are still alive.
        for process in self.processes:
            if process.is_alive():
                process.terminate()
            process.join()
    
        # There won't be an error on the queue if the process crashed.
        failed_process = self.processes[error_index]
        if self.error_queues[error_index].empty():
            exitcode = self.processes[error_index].exitcode
            if exitcode &lt; 0:
                name = signal.Signals(-exitcode).name
                raise ProcessExitedException(
                    "process %d terminated with signal %s" % (error_index, name),
                    error_index=error_index,
                    error_pid=failed_process.pid,
                    exit_code=exitcode,
                    signal_name=name,
                )
            else:
                raise ProcessExitedException(
                    "process %d terminated with exit code %d" % (error_index, exitcode),
                    error_index=error_index,
                    error_pid=failed_process.pid,
                    exit_code=exitcode,
                )
    
        original_trace = self.error_queues[error_index].get()
        msg = "\n\n-- Process %d terminated with the following error:\n" % error_index
        msg += original_trace
&gt;       raise ProcessRaisedException(msg, error_index, failed_process.pid)
E       torch.multiprocessing.spawn.ProcessRaisedException: 
E       
E       -- Process 0 terminated with the following error:
E       Traceback (most recent call last):
E         File "/home/c-jjian/assignments/spring2024-assignment2-systems/336_a2_test_venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 68, in _wrap
E           fn(i, *args)
E         File "/home/c-jjian/assignments/spring2024-assignment2-systems/cs336-systems/tests/test_sharded_optimizer.py", line 48, in _test_sharded_optimizer
E           sharded_optimizer = get_sharded_optimizer(
E         File "/home/c-jjian/assignments/spring2024-assignment2-systems/cs336-systems/tests/adapters.py", line 194, in get_sharded_optimizer
E           raise NotImplementedError
E       NotImplementedError

336_a2_test_venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:158: ProcessRaisedException</failure></testcase><testcase classname="tests.test_sharded_optimizer" name="test_sharded_optimizer[ToyModelWithTiedWeights]" time="3.368"><failure message="torch.multiprocessing.spawn.ProcessRaisedException: &#10;&#10;-- Process 1 terminated with the following error:&#10;Traceback (most recent call last):&#10;  File &quot;/home/c-jjian/assignments/spring2024-assignment2-systems/336_a2_test_venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py&quot;, line 68, in _wrap&#10;    fn(i, *args)&#10;  File &quot;/home/c-jjian/assignments/spring2024-assignment2-systems/cs336-systems/tests/test_sharded_optimizer.py&quot;, line 48, in _test_sharded_optimizer&#10;    sharded_optimizer = get_sharded_optimizer(&#10;  File &quot;/home/c-jjian/assignments/spring2024-assignment2-systems/cs336-systems/tests/adapters.py&quot;, line 194, in get_sharded_optimizer&#10;    raise NotImplementedError&#10;NotImplementedError">model_class = &lt;class 'tests.common.ToyModelWithTiedWeights'&gt;

    @pytest.mark.parametrize("model_class", [ToyModel, ToyModelWithTiedWeights])
    def test_sharded_optimizer(model_class):
        world_size = 2
&gt;       mp.spawn(
            _test_sharded_optimizer,
            args=(world_size, model_class),
            nprocs=world_size,
            join=True,
        )

cs336-systems/tests/test_sharded_optimizer.py:22: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
336_a2_test_venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:241: in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method="spawn")
336_a2_test_venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:197: in start_processes
    while not context.join():
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;torch.multiprocessing.spawn.ProcessContext object at 0x1532a483b640&gt;, timeout = None

    def join(self, timeout=None):
        r"""Join one or more processes within spawn context.
    
        Attempt to join one or more processes in this spawn context.
        If one of them exited with a non-zero exit status, this function
        kills the remaining processes and raises an exception with the cause
        of the first process exiting.
    
        Returns ``True`` if all processes have been joined successfully,
        ``False`` if there are more processes that need to be joined.
    
        Args:
            timeout (float): Wait this long before giving up on waiting.
        """
        # Ensure this function can be called even when we're done.
        if len(self.sentinels) == 0:
            return True
    
        # Wait for any process to fail or all of them to succeed.
        ready = multiprocessing.connection.wait(
            self.sentinels.keys(),
            timeout=timeout,
        )
    
        error_index = None
        for sentinel in ready:
            index = self.sentinels.pop(sentinel)
            process = self.processes[index]
            process.join()
            if process.exitcode != 0:
                error_index = index
                break
    
        # Return if there was no error.
        if error_index is None:
            # Return whether or not all processes have been joined.
            return len(self.sentinels) == 0
    
        # Assume failure. Terminate processes that are still alive.
        for process in self.processes:
            if process.is_alive():
                process.terminate()
            process.join()
    
        # There won't be an error on the queue if the process crashed.
        failed_process = self.processes[error_index]
        if self.error_queues[error_index].empty():
            exitcode = self.processes[error_index].exitcode
            if exitcode &lt; 0:
                name = signal.Signals(-exitcode).name
                raise ProcessExitedException(
                    "process %d terminated with signal %s" % (error_index, name),
                    error_index=error_index,
                    error_pid=failed_process.pid,
                    exit_code=exitcode,
                    signal_name=name,
                )
            else:
                raise ProcessExitedException(
                    "process %d terminated with exit code %d" % (error_index, exitcode),
                    error_index=error_index,
                    error_pid=failed_process.pid,
                    exit_code=exitcode,
                )
    
        original_trace = self.error_queues[error_index].get()
        msg = "\n\n-- Process %d terminated with the following error:\n" % error_index
        msg += original_trace
&gt;       raise ProcessRaisedException(msg, error_index, failed_process.pid)
E       torch.multiprocessing.spawn.ProcessRaisedException: 
E       
E       -- Process 1 terminated with the following error:
E       Traceback (most recent call last):
E         File "/home/c-jjian/assignments/spring2024-assignment2-systems/336_a2_test_venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py", line 68, in _wrap
E           fn(i, *args)
E         File "/home/c-jjian/assignments/spring2024-assignment2-systems/cs336-systems/tests/test_sharded_optimizer.py", line 48, in _test_sharded_optimizer
E           sharded_optimizer = get_sharded_optimizer(
E         File "/home/c-jjian/assignments/spring2024-assignment2-systems/cs336-systems/tests/adapters.py", line 194, in get_sharded_optimizer
E           raise NotImplementedError
E       NotImplementedError

336_a2_test_venv/lib/python3.10/site-packages/torch/multiprocessing/spawn.py:158: ProcessRaisedException</failure></testcase></testsuite></testsuites>